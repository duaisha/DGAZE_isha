{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input, Merge, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import SGD, Adam, Adamax\n",
    "from keras.models import model_from_yaml\n",
    "from keras.regularizers import l1, l2\n",
    "from load_dataset import get_data, dataset\n",
    "from utils import print_metadata, get_dgaze_frames_count, split_data, plot_gaze_points, save_model, load_model\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import cv2 \n",
    "\n",
    "from numpy.random import seed\n",
    "seed(3)\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)\n",
    "\n",
    "import random \n",
    "random.seed(1)\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "# from keras import backend as k\n",
    "# import tensorflow as tf\n",
    "# config = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1,\n",
    "# allow_soft_placement=True, device_count = {'CPU': 1})\n",
    "# sess = tf.Session(graph=tf.get_default_graph(),config=config)\n",
    "# k.set_session(sess)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:05<00:00,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total frames in DGAZE dataset is 227178\n",
      "List of Features: ['face_location', 'gaze_point', 'headpose_pupil', 'right_eye', 'left_eye']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = '/ssd_scratch/cvit/isha/eye_gaze_mapping/DGM_final2/dataset_samples_callibrated/'\n",
    "model_save = '/ssd_scratch/cvit/isha/DGAZE2/DGAZE_weights/weights_lefteye'\n",
    "drivers = os.listdir(data_path)\n",
    "ndrivers = len(drivers)\n",
    "sequences = 112\n",
    "\n",
    "# Driver_data is dict contatining drivers user1, user 2.....etc. For each driver, we have 112 sequences and for   \n",
    "# each sequence we have features like ['face_location', 'headpose_pupil', 'left_eye', 'gaze_point', 'right_eye'] \n",
    "driver_data = get_data(data_path, drivers, sequences)\n",
    "\n",
    "# Print the total numer of frames in the dataset\n",
    "get_dgaze_frames_count(driver_data, drivers)\n",
    "\n",
    "# Prints the DGAZE Metadata including list of drivers, sequences and features \n",
    "#print_metadata(driver_data, ['drivers', 'sequences', 'features'])\n",
    "print_metadata(driver_data, ['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_range = np.arange(10, sequences+1)\n",
    "nsequences = len(seq_range)\n",
    "ndrivers = len(drivers)\n",
    "random.shuffle(drivers)\n",
    "\n",
    "dsplit = [int(0.8*ndrivers),int(0.1*ndrivers), int(0.1*ndrivers)]\n",
    "gp_split = [int(0.6*nsequences),int(0.2*nsequences), int(0.2*nsequences)]\n",
    "data_split = split_data(drivers, seq_range, dsplit, gp_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataset\n",
    "train = dataset(driver_data, data_split['drivers_train'], data_split['sequence_train'])\n",
    "\n",
    "# Validation dataset\n",
    "val = dataset(driver_data, data_split['drivers_val'], data_split['sequence_val'])\n",
    "\n",
    "# Test dataset\n",
    "test = dataset(driver_data, data_split['drivers_test'], data_split['sequence_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train['left_eye'].shape, train['right_eye'].shape, train['headpose_pupil'].shape, \\\n",
    "      train['face_location'].shape, train['face_features'].shape, train['gaze_point'].shape)\n",
    "\n",
    "print(val['left_eye'].shape, val['right_eye'].shape, val['headpose_pupil'].shape, \\\n",
    "      val['face_location'].shape, val['face_features'].shape, val['gaze_point'].shape)\n",
    "\n",
    "print(test['left_eye'].shape, test['right_eye'].shape, test['headpose_pupil'].shape, \\\n",
    "      test['face_location'].shape, test['face_features'].shape, test['gaze_point'].shape)\n",
    "\n",
    "print(\"Total number of frames -->\",train['gaze_point'].shape[0] + val['gaze_point'].shape[0]\\\n",
    "      + test['gaze_point'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gaze_points(data_path, train['gaze_point'])\n",
    "plot_gaze_points(data_path, val['gaze_point'])\n",
    "plot_gaze_points(data_path, test['gaze_point'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = ['user2']\n",
    "data_path = '/ssd_scratch/cvit/isha/eye_gaze_mapping/DGM_final2/dataset_samples_callibrated/'\n",
    "\n",
    "for i in range(112, 113):\n",
    "    cap = cv2.VideoCapture(data_path + driver[0] + '/original_road_view/sample_'+str(i)+'.avi')\n",
    "    ret, frame = cap.read()\n",
    "    for j in range(150):\n",
    "        ret, frame = cap.read()\n",
    "    print(i, frame.shape)\n",
    "    plt.figure()\n",
    "    plt.imshow(frame)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {}\n",
    "dict['CAR'] =[10, 11, 13, 16, 21, 26,34, 36,38, 39, 40, 42, 44, 47, 49, 50, 54, 56,58, 59, 60, 61, 65, 66, 74,\n",
    "              75, 78, 81,  83]\n",
    "dict['MB'] = [12,18,20,22,24, 29,30, 32,33, 35,45, 48, 51, 55,62, 64, 67,70, 71, 89, 90,94,97,98 , 106,111,   ]\n",
    "dict['SB'] =[14,27,31, 37, 68, 73, 86,88, 92,  108, ]\n",
    "dict['TS'] = [15,52,53, 77, 80, 85, 93, 100,102, 109, 110, ]\n",
    "dict['AR'] = [25, 28, 41, 69,84, 87, 91, 96, 107, ]\n",
    "dict['P'] = [19,23,43, 46, 57, 63, 72, 76, 82, 99,101,103, 104, 105, 112]\n",
    "dict['BL'] =[17, 79, 95, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset(driver_data, 'user2', data_split['sequence_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in data_split['drivers_val']:\n",
    "    data_calibrate = dataset(driver_data, [d], np.arange(12,13))\n",
    "#     x = data_calibrate['face_location']\n",
    "#     y = data_calibrate['headpose_pupil']\n",
    "\n",
    "    cap = cv2.VideoCapture(data_path + d + '/original_road_view/sample_10.avi')\n",
    "    ret, frame = cap.read()\n",
    "    plt.figure()\n",
    "#     cv2.rectangle(frame, (x[0,2], x[0,0]), (x[0,3], x[0,1]), (255, 255, 255), 6)\n",
    "#     cv2.circle(frame,(int(y[0,6]), int(y[0,7])),3,(255,255,0),40)\n",
    "#     cv2.circle(frame,(int(y[0,4]), int(y[0,5])),3,(255,255,0),40)\n",
    "#     cv2.circle(frame,(int(y[0,9]), int(y[0,10])),3,(255,255,0),40)\n",
    "    plt.imshow(frame)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.MinMaxScaler()\n",
    "train['face_features'] = scaler.fit_transform(train['face_features'])\n",
    "val['face_features'] = scaler.transform(val['face_features'])\n",
    "test['face_features'] = scaler.transform(test['face_features'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['left_eye']= train['left_eye'].reshape(-1, 36,60,1)\n",
    "val['left_eye']= val['left_eye'].reshape(-1, 36,60,1)\n",
    "test['left_eye']= test['left_eye'].reshape(-1, 36,60,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['right_eye']= train['right_eye'].reshape(-1, 36,60,1)\n",
    "val['right_eye']= val['right_eye'].reshape(-1, 36,60,1)\n",
    "test['right_eye']= test['right_eye'].reshape(-1, 36,60,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lefteye = Sequential()\n",
    "model_lefteye.add(Conv2D(20, kernel_size=(3, 3),activation='relu',input_shape=(36,60,1), activity_regularizer=l1(0.01),  kernel_regularizer=l2(0.02), bias_regularizer=l2(0.02)))\n",
    "model_lefteye.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_lefteye.add(Dropout(0.5))\n",
    "model_lefteye.add(Conv2D(50, (3, 3), activation='relu',activity_regularizer=l1(0.01),  kernel_regularizer=l2(0.02), bias_regularizer=l2(0.02)))\n",
    "model_lefteye.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_lefteye.add(Flatten())\n",
    "\n",
    "\n",
    "model_righteye = Sequential()\n",
    "model_righteye.add(Conv2D(20, kernel_size=(3, 3),activation='relu',input_shape=(36,60,1), activity_regularizer=l1(0.001),  kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "model_righteye.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_righteye.add(Dropout(0.5))\n",
    "model_righteye.add(Conv2D(50, (3, 3), activation='relu',activity_regularizer=l1(0.001),  kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "model_righteye.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_righteye.add(Flatten())\n",
    "\n",
    "\n",
    "# model_facefeatures = Sequential()\n",
    "# model_facefeatures.add(Dense(16, activation ='relu', input_dim=(10)))\n",
    "\n",
    "model_merge = Sequential()\n",
    "model_merge.add(Merge([model_lefteye, model_righteye], mode = 'concat'))\n",
    "model_merge.add(Dense(512, activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "#model_merge.add(Dense(256, activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "model_merge.add(Dense(2, activation=\"linear\"))\n",
    "print(model_merge.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr = 0.0001)\n",
    "model_merge.compile(loss = 'mae', optimizer = opt )\n",
    "earlystopping = keras.callbacks.EarlyStopping(monitor = 'val_loss',min_delta = 1, patience =3, verbose =0, mode ='auto')\n",
    "\n",
    "history = model_merge.fit([train['left_eye'], train['right_eye']], train['gaze_point'][:,:2], \\\n",
    "                validation_data= ([val['left_eye'], val['right_eye']],val['gaze_point'][:,:2]),\n",
    "                epochs = 200, batch_size = 256, verbose=1, shuffle= True)\n",
    "\n",
    "save_model(model_save, model_merge)\n",
    "\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save = '/ssd_scratch/cvit/isha/DGAZE2/DGAZE_weights/weights_lefteye_righteye'\n",
    "save_model(model_save, model_merge)\n",
    "\n",
    "print(history.history.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr = 0.0001)\n",
    "\n",
    "\n",
    "model_merge.compile(loss = 'mae', optimizer = opt )\n",
    "earlystopping = keras.callbacks.EarlyStopping(monitor = 'val_loss',min_delta = 1, patience =3, verbose =0, mode ='auto')\n",
    "\n",
    "history = model_merge.fit([train['left_eye'], train['right_eye']], train['gaze_point'][:,:2], \\\n",
    "                validation_data= ([val['left_eye'], val['right_eye']],val['gaze_point'][:,:2]),\n",
    "                epochs = 200, batch_size = 256, verbose=1, shuffle= True)\n",
    "\n",
    "save_model(model_save, model_merge)\n",
    "\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save = '/ssd_scratch/cvit/isha/DGAZE2/DGAZE_weights/weights_lefteye_righteye'\n",
    "opt = Adam(lr=0.0001)\n",
    "model_merge = load_model(model_save)\n",
    "model_merge.compile(loss='mae', optimizer=opt)\n",
    "\n",
    "history = model_merge.fit([train['left_eye'], train['right_eye']], train['gaze_point'][:,:2], \\\n",
    "                validation_data= ([val['left_eye'], val['right_eye']],val['gaze_point'][:,:2]),\n",
    "                epochs = 200, batch_size = 32, verbose=1, shuffle= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaze_error(model, data):\n",
    "    scores = model.evaluate([data['left_eye'], data['right_eye']], data['gaze_point'][:,:2])\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save = '/ssd_scratch/cvit/isha/DGAZE2/DGAZE_weights/weights_lefteye_righteye'\n",
    "opt = Adam(lr=0.00001)\n",
    "model_merge = load_model(model_save)\n",
    "model_merge.compile(loss='mae', optimizer=opt)\n",
    "\n",
    "train_error = gaze_error(model_merge, train)\n",
    "val_error = gaze_error(model_merge, val)\n",
    "test_error = gaze_error(model_merge, test)\n",
    "    \n",
    "print(\"Train Error ==> \", train_error)\n",
    "print(\"Val Error ==> \",  val_error)\n",
    "print(\"Test Error ==> \" ,test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
