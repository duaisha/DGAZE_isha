{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input, Merge, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import SGD, Adam, Adamax\n",
    "from keras.models import model_from_yaml\n",
    "from keras.regularizers import l1, l2\n",
    "from load_dataset import get_data, dataset\n",
    "from utils import print_metadata, get_dgaze_frames_count, split_data, plot_gaze_points, save_model, load_model\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import cv2 \n",
    "\n",
    "from numpy.random import seed\n",
    "seed(33)\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(26)\n",
    "\n",
    "import random \n",
    "random.seed(10)\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "# from keras import backend as k\n",
    "# import tensorflow as tf\n",
    "# config = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1,\n",
    "# allow_soft_placement=True, device_count = {'CPU': 1})\n",
    "# sess = tf.Session(graph=tf.get_default_graph(),config=config)\n",
    "# k.set_session(sess)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/ssd_scratch/cvit/isha/eye_gaze_mapping/DGM_final2/dataset_samples_callibrated/'\n",
    "model_save = '/ssd_scratch/cvit/isha/DGAZE2/DGAZE_weights/weights_proposed_approach_lefteye_righteye_FF'\n",
    "drivers = os.listdir(data_path)\n",
    "ndrivers = len(drivers)\n",
    "sequences = 112\n",
    "\n",
    "# Driver_data is dict contatining drivers user1, user 2.....etc. For each driver, we have 112 sequences and for   \n",
    "# each sequence we have features like ['face_location', 'headpose_pupil', 'left_eye', 'gaze_point', 'right_eye'] \n",
    "driver_data = get_data(data_path, drivers, sequences)\n",
    "\n",
    "# Print the total numer of frames in the dataset\n",
    "get_dgaze_frames_count(driver_data, drivers)\n",
    "\n",
    "# Prints the DGAZE Metadata including list of drivers, sequences and features \n",
    "#print_metadata(driver_data, ['drivers', 'sequences', 'features'])\n",
    "print_metadata(driver_data, ['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_range = np.arange(10, sequences+1)\n",
    "nsequences = len(seq_range)\n",
    "ndrivers = len(drivers)\n",
    "random.shuffle(drivers)\n",
    "\n",
    "dsplit = [int(0.8*ndrivers),int(0.1*ndrivers), int(0.1*ndrivers)]\n",
    "gp_split = [int(0.6*nsequences),int(0.2*nsequences), int(0.2*nsequences)]\n",
    "data_split = split_data(drivers, seq_range, dsplit, gp_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataset\n",
    "train = dataset(driver_data, data_split['drivers_train'], data_split['sequence_train'])\n",
    "\n",
    "# Validation dataset\n",
    "val = dataset(driver_data, data_split['drivers_val'], data_split['sequence_val'])\n",
    "\n",
    "# Test dataset\n",
    "test = dataset(driver_data, data_split['drivers_test'], data_split['sequence_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train['left_eye'].shape, train['right_eye'].shape, train['headpose_pupil'].shape, \\\n",
    "      train['face_location'].shape, train['face_features'].shape, train['gaze_point'].shape)\n",
    "\n",
    "print(val['left_eye'].shape, val['right_eye'].shape, val['headpose_pupil'].shape, \\\n",
    "      val['face_location'].shape, val['face_features'].shape, val['gaze_point'].shape)\n",
    "\n",
    "print(test['left_eye'].shape, test['right_eye'].shape, test['headpose_pupil'].shape, \\\n",
    "      test['face_location'].shape, test['face_features'].shape, test['gaze_point'].shape)\n",
    "\n",
    "print(\"Total number of frames -->\",train['gaze_point'].shape[0] + val['gaze_point'].shape[0]\\\n",
    "      + test['gaze_point'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gaze_points(data_path, train['gaze_point'])\n",
    "plot_gaze_points(data_path, val['gaze_point'])\n",
    "plot_gaze_points(data_path, test['gaze_point'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for d in data_split['drivers_val']:\n",
    "    data_calibrate = dataset(driver_data, [d], np.arange(12,13))\n",
    "    x = data_calibrate['face_location']\n",
    "    y = data_calibrate['headpose_pupil']\n",
    "    print(data_calibrate['face_features'][0])\n",
    "\n",
    "    cap = cv2.VideoCapture(data_path + d + '/driver_view/sample_10.avi')\n",
    "    ret, frame = cap.read()\n",
    "    plt.figure()\n",
    "    cv2.rectangle(frame, (x[0,2], x[0,0]), (x[0,3], x[0,1]), (255, 255, 255), 6)\n",
    "    cv2.circle(frame,(int(y[0,6]), int(y[0,7])),3,(255,255,0),40)\n",
    "    cv2.circle(frame,(int(y[0,4]), int(y[0,5])),3,(255,255,0),40)\n",
    "    cv2.circle(frame,(int(y[0,9]), int(y[0,10])),3,(255,255,0),40)\n",
    "    plt.imshow(frame)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = preprocessing.MinMaxScaler()\n",
    "# train['face_features'] = scaler.fit_transform(train['face_features'])\n",
    "# val['face_features'] = scaler.transform(val['face_features'])\n",
    "# test['face_features'] = scaler.transform(test['face_features'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_lefteye = Sequential()\n",
    "model_lefteye.add(Conv2D(20, kernel_size=(3, 3),activation='relu',input_shape=(36,60,3)))\n",
    "model_lefteye.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_lefteye.add(Dropout(0.5))\n",
    "model_lefteye.add(Conv2D(50, (3, 3), activation='relu'))\n",
    "model_lefteye.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_lefteye.add(Flatten())\n",
    "\n",
    "model_righteye = Sequential()\n",
    "model_righteye.add(Conv2D(20, kernel_size=(3, 3),activation='relu',input_shape=(36,60,3)))\n",
    "model_righteye.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_righteye.add(Dropout(0.5))\n",
    "model_righteye.add(Conv2D(50, (3, 3), activation='relu'))\n",
    "model_righteye.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_righteye.add(Flatten())\n",
    "\n",
    "model_facefeatures = Sequential()\n",
    "model_facefeatures.add(Dense(16, activation ='relu', input_dim=(10)))\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(Merge([model_lefteye, model_righteye], mode = 'concat'))\n",
    "model3.add(Dense(500, activation='relu'))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Merge([model3, model_facefeatures], mode = 'concat'))\n",
    "model.add(Dense(258, activation='relu'))\n",
    "#model_merge.add(Dense(256, activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "model.add(Dense(2, activation=\"linear\"))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.001, decay=0.1 / 200)\n",
    "model.compile(loss = 'mae', optimizer = opt )\n",
    "earlystopping = keras.callbacks.EarlyStopping(monitor = 'val_loss',min_delta = 1, patience =10, verbose =0, mode ='auto')\n",
    "\n",
    "history = model.fit([train['left_eye'], train['right_eye'], train['face_features'][:,:10]], train['gaze_point'][:,:2], \\\n",
    "                validation_data= ([val['left_eye'], val['right_eye'], val['face_features'][:,:10]],val['gaze_point'][:,:2]),\n",
    "                epochs = 200, batch_size = 32,  callbacks =[earlystopping], verbose=1, shuffle= True)\n",
    "\n",
    "save_model(model_save, model)\n",
    "\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit([train['left_eye'], train['right_eye'], train['face_features'][:,:10]], train['gaze_point'][:,:2], \\\n",
    "                validation_data= ([val['left_eye'], val['right_eye'], val['face_features'][:,:10]],val['gaze_point'][:,:2]),\n",
    "                epochs = 200, batch_size = 32,  callbacks =[earlystopping], verbose=1, shuffle= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'][1:])\n",
    "plt.plot(history.history['val_loss'][1:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model_save, model)\n",
    "\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaze_error(model, data):\n",
    "    scores = model.evaluate([data['left_eye'], data['right_eye'], data['face_features'][:,:10]], data['gaze_point'][:,:2])\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(model_save)\n",
    "model.compile(loss='mae', optimizer=opt)\n",
    "\n",
    "train_error = gaze_error(model, train)\n",
    "val_error = gaze_error(model, val)\n",
    "test_error = gaze_error(model, test)\n",
    "    \n",
    "print(\"Train Error ==> \", train_error)\n",
    "print(\"Val Error ==> \",  val_error)\n",
    "print(\"Test Error ==> \" ,test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for driver in data_split['drivers_test']:\n",
    "\n",
    "#     data_calibrate = dataset(driver_data, [driver], np.arange(1,113))\n",
    "#     model_merge = load_model(model_save)\n",
    "    \n",
    "#     opt = Adam(lr=0.001, decay=0.1 / 200)\n",
    "#     model_merge.compile(loss='mae', optimizer=opt)\n",
    "#     scores = model_merge.evaluate([data_calibrate['left_eye'][2000:], data_calibrate['face_features'][2000:]], data_calibrate['gaze_point'][2000:,:2])\n",
    "#     print(\"====> Before Calibration\", scores)                   \n",
    "\n",
    "#     history = model_merge.fit([data_calibrate['left_eye'][:2000], data_calibrate['face_features'][:2000]], data_calibrate['gaze_point'][:2000,:2], \\\n",
    "#                     validation_data= ([data_calibrate['left_eye'][2000:], data_calibrate['face_features'][2000:]],data_calibrate['gaze_point'][2000:,:2]),\n",
    "#                     epochs = 20, batch_size = 32, verbose=1, shuffle= True)\n",
    "\n",
    "#     scores = model_merge.evaluate([data_calibrate['left_eye'][2000:], data_calibrate['face_features'][2000:]], data_calibrate['gaze_point'][2000:,:2])\n",
    "\n",
    "#     print(\"====> After Calibration\", scores) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te_error = 0; tr_error = 0\n",
    "for driver in data_split['drivers_val']:\n",
    "    data_calibrate = dataset(driver_data, [driver], np.arange(1,15))\n",
    "                         \n",
    "    te_calibrate = dataset(driver_data, [driver], data_split['sequence_val'])\n",
    "\n",
    "    print(te_calibrate['gaze_point'].shape)\n",
    "    opt = Adam(lr=0.0001, decay=0.1 / 200)\n",
    "    \n",
    "    model_merge = load_model(model_save)\n",
    "    for layer in model_merge.layers[:1]:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    model_merge.compile(loss = 'mae', optimizer = opt)\n",
    "    \n",
    "    error = gaze_error(model_merge, te_calibrate)\n",
    "    tr_error += error\n",
    "    print(\"Test Error ==> \" ,error)\n",
    "              \n",
    "\n",
    "        \n",
    "    model_merge.fit([data_calibrate['left_eye'], data_calibrate['right_eye']], data_calibrate['gaze_point'][:,:2], \\\n",
    "                validation_data= ([te_calibrate['left_eye'], te_calibrate['right_eye']],te_calibrate['gaze_point'][:,:2]),\n",
    "                epochs = 10, batch_size = 8, callbacks = [earlystopping], verbose=1, shuffle= True)\n",
    "\n",
    "\n",
    "    error = gaze_error(model_merge, te_calibrate)\n",
    "    te_error += error\n",
    "    print(\"Test Error ==> \" ,error)\n",
    "                         \n",
    "print(\"Total test error -->\", tr_error/len(data_split['drivers_val']), te_error/len(data_split['drivers_val']))\n",
    "                         \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te_error = 0; tr_error = 0\n",
    "for driver in data_split['drivers_test']:\n",
    "    data_calibrate = dataset(driver_data, [driver], np.arange(1,15))\n",
    "                         \n",
    "    te_calibrate = dataset(driver_data, [driver], data_split['sequence_test'])\n",
    "\n",
    "    print(te_calibrate['gaze_point'].shape)\n",
    "    \n",
    "    opt = Adam(lr=0.00001, decay=0.1 / 200)\n",
    "    \n",
    "    model_merge = load_model(model_save)\n",
    "    for layer in model_merge.layers[:1]:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    model_merge.compile(loss = 'mae', optimizer = opt)\n",
    "    \n",
    "    error = gaze_error(model_merge, te_calibrate)\n",
    "    tr_error += error\n",
    "    print(\"Test Error ==> \" ,error)\n",
    "              \n",
    "\n",
    "        \n",
    "    model_merge.fit([data_calibrate['left_eye'], data_calibrate['right_eye']], data_calibrate['gaze_point'][:,:2], \\\n",
    "                validation_data= ([te_calibrate['left_eye'], te_calibrate['right_eye']],te_calibrate['gaze_point'][:,:2]),\n",
    "                epochs = 10, batch_size = 16, verbose=1, shuffle= True)\n",
    "\n",
    "\n",
    "    error = gaze_error(model_merge, te_calibrate)\n",
    "    te_error += error\n",
    "    print(\"Test Error ==> \" ,error)\n",
    "                         \n",
    "print(\"Total test error -->\", tr_error/len(data_split['drivers_test']), te_error/len(data_split['drivers_val']))\n",
    "                         \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
