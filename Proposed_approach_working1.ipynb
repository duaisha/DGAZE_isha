{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input, Merge, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import SGD, Adam, Adamax\n",
    "from keras.models import model_from_yaml\n",
    "from keras.regularizers import l1, l2\n",
    "from load_dataset import get_data, dataset\n",
    "from utils import print_metadata, get_dgaze_frames_count, split_data, plot_gaze_points, save_model, load_model\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import cv2 \n",
    "\n",
    "from numpy.random import seed\n",
    "seed(33)\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(26)\n",
    "\n",
    "import random \n",
    "random.seed(10)\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# from keras import backend as k\n",
    "# import tensorflow as tf\n",
    "# config = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1,\n",
    "# allow_soft_placement=True, device_count = {'CPU': 1})\n",
    "# sess = tf.Session(graph=tf.get_default_graph(),config=config)\n",
    "# k.set_session(sess)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:06<00:00,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total frames in DGAZE dataset is 227178\n",
      "List of Features: ['right_eye', 'gaze_point', 'left_eye', 'headpose_pupil', 'face_location']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = '/ssd_scratch/cvit/isha/eye_gaze_mapping/DGM_final2/dataset_samples_callibrated/'\n",
    "model_save = '/ssd_scratch/cvit/isha/DGAZE2/DGAZE_weights/weights_proposed_approach_normalized'\n",
    "drivers = os.listdir(data_path)\n",
    "ndrivers = len(drivers)\n",
    "sequences = 112\n",
    "\n",
    "# Driver_data is dict contatining drivers user1, user 2.....etc. For each driver, we have 112 sequences and for   \n",
    "# each sequence we have features like ['face_location', 'headpose_pupil', 'left_eye', 'gaze_point', 'right_eye'] \n",
    "driver_data = get_data(data_path, drivers, sequences)\n",
    "\n",
    "# Print the total numer of frames in the dataset\n",
    "get_dgaze_frames_count(driver_data, drivers)\n",
    "\n",
    "# Prints the DGAZE Metadata including list of drivers, sequences and features \n",
    "#print_metadata(driver_data, ['drivers', 'sequences', 'features'])\n",
    "print_metadata(driver_data, ['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_range = np.arange(10, sequences+1)\n",
    "nsequences = len(seq_range)\n",
    "ndrivers = len(drivers)\n",
    "random.shuffle(drivers)\n",
    "\n",
    "dsplit = [int(0.8*ndrivers),int(0.1*ndrivers), int(0.1*ndrivers)]\n",
    "gp_split = [int(0.6*nsequences),int(0.2*nsequences), int(0.2*nsequences)]\n",
    "data_split = split_data(drivers, seq_range, dsplit, gp_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'drivers_test': ['user17', 'user19'],\n",
       " 'drivers_train': ['user24',\n",
       "  'user23',\n",
       "  'user22',\n",
       "  'user12',\n",
       "  'user18',\n",
       "  'user2',\n",
       "  'user8',\n",
       "  'user13',\n",
       "  'user5',\n",
       "  'user3',\n",
       "  'user10',\n",
       "  'user21',\n",
       "  'user16',\n",
       "  'user11',\n",
       "  'user14',\n",
       "  'user15'],\n",
       " 'drivers_val': ['user20', 'user7'],\n",
       " 'sequence_test': array([ 84,  15, 109,  88,  66,  40, 104, 112,  56,  94,  48,  97,  32,\n",
       "         68,  43,  96,  46,  63,  58,  55]),\n",
       " 'sequence_train': array([ 49, 102,  28,  83,  26, 108,  57,  79,  11,  39, 105,  93,  91,\n",
       "         95,  45,  90,  53,  23,  82,  81,  61, 110,  35,  75,  31,  60,\n",
       "         42,  24,  77,  13,  47,  21,  54, 100,  85,  76,  71,  37, 103,\n",
       "         22,  20,  73,  16,  17,  59,  64,  33, 107, 111,  19,  92,  44,\n",
       "         14,  52,  86,  62,  29,  41,  69,  12,  25]),\n",
       " 'sequence_val': array([ 36,  72,  38,  30,  74,  51,  18,  70,  65,  67,  80,  50,  89,\n",
       "         99,  78, 101,  34,  98, 106,  10])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [00:00<00:00, 118.88it/s]\n",
      "100%|██████████| 61/61 [00:00<00:00, 251.68it/s]\n",
      "100%|██████████| 61/61 [00:01<00:00, 40.46it/s] \n",
      "100%|██████████| 61/61 [00:00<00:00, 77.60it/s] \n",
      "100%|██████████| 61/61 [00:01<00:00, 55.22it/s] \n",
      "100%|██████████| 61/61 [00:01<00:00, 33.17it/s] \n",
      "100%|██████████| 61/61 [00:01<00:00, 55.23it/s] \n",
      "100%|██████████| 61/61 [00:00<00:00, 69.95it/s] \n",
      "100%|██████████| 61/61 [00:00<00:00, 66.51it/s] \n",
      "100%|██████████| 61/61 [00:01<00:00, 54.17it/s] \n",
      "100%|██████████| 61/61 [00:00<00:00, 86.73it/s] \n",
      "100%|██████████| 61/61 [00:00<00:00, 114.62it/s]\n",
      "100%|██████████| 61/61 [00:01<00:00, 54.19it/s] \n",
      "100%|██████████| 61/61 [00:00<00:00, 76.95it/s] \n",
      "100%|██████████| 61/61 [00:01<00:00, 32.26it/s] \n",
      "100%|██████████| 61/61 [00:01<00:00, 32.27it/s] \n",
      "100%|██████████| 16/16 [00:22<00:00,  1.85s/it]\n",
      "100%|██████████| 20/20 [00:00<00:00, 196.53it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 121.38it/s]\n"
     ]
    }
   ],
   "source": [
    "# Training dataset\n",
    "train = dataset(driver_data, data_split['drivers_train'], data_split['sequence_train'])\n",
    "\n",
    "# Validation dataset\n",
    "val = dataset(driver_data, data_split['drivers_val'], data_split['sequence_val'])\n",
    "\n",
    "# Test dataset\n",
    "test = dataset(driver_data, data_split['drivers_test'], data_split['sequence_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train['left_eye'].shape, train['right_eye'].shape, train['headpose_pupil'].shape, \\\n",
    "      train['face_location'].shape, train['face_features'].shape, train['gaze_point'].shape)\n",
    "\n",
    "print(val['left_eye'].shape, val['right_eye'].shape, val['headpose_pupil'].shape, \\\n",
    "      val['face_location'].shape, val['face_features'].shape, val['gaze_point'].shape)\n",
    "\n",
    "print(test['left_eye'].shape, test['right_eye'].shape, test['headpose_pupil'].shape, \\\n",
    "      test['face_location'].shape, test['face_features'].shape, test['gaze_point'].shape)\n",
    "\n",
    "print(\"Total number of frames -->\",train['gaze_point'].shape[0] + val['gaze_point'].shape[0]\\\n",
    "      + test['gaze_point'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gaze_points(data_path, train['gaze_point'])\n",
    "plot_gaze_points(data_path, val['gaze_point'])\n",
    "plot_gaze_points(data_path, test['gaze_point'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for d in data_split['drivers_val']:\n",
    "    data_calibrate = dataset(driver_data, [d], np.arange(12,13))\n",
    "    x = data_calibrate['face_location']\n",
    "    y = data_calibrate['headpose_pupil']\n",
    "    print(data_calibrate['face_features'][0])\n",
    "\n",
    "    cap = cv2.VideoCapture(data_path + d + '/driver_view/sample_10.avi')\n",
    "    ret, frame = cap.read()\n",
    "    plt.figure()\n",
    "    cv2.rectangle(frame, (x[0,2], x[0,0]), (x[0,3], x[0,1]), (255, 255, 255), 6)\n",
    "    cv2.circle(frame,(int(y[0,6]), int(y[0,7])),3,(255,255,0),40)\n",
    "    cv2.circle(frame,(int(y[0,4]), int(y[0,5])),3,(255,255,0),40)\n",
    "    cv2.circle(frame,(int(y[0,9]), int(y[0,10])),3,(255,255,0),40)\n",
    "    plt.imshow(frame)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = preprocessing.MinMaxScaler()\n",
    "# train['face_features'] = scaler.fit_transform(train['face_features'])\n",
    "# val['face_features'] = scaler.transform(val['face_features'])\n",
    "# test['face_features'] = scaler.transform(test['face_features'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lefteye = Sequential()\n",
    "model_lefteye.add(Conv2D(20, kernel_size=(3, 3),activation='relu',input_shape=(36,60,3)))\n",
    "model_lefteye.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_lefteye.add(Dropout(0.5))\n",
    "model_lefteye.add(Conv2D(50, (3, 3), activation='relu'))\n",
    "model_lefteye.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_lefteye.add(Flatten())\n",
    "\n",
    "\n",
    "model_facefeatures = Sequential()\n",
    "model_facefeatures.add(Dense(16, activation ='relu', input_dim=(14)))\n",
    "\n",
    "model_merge = Sequential()\n",
    "model_merge.add(Merge([model_lefteye, model_facefeatures], mode = 'concat'))\n",
    "model_merge.add(Dense(500, activation='relu'))\n",
    "#model_merge.add(Dense(256, activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "model_merge.add(Dense(2, activation=\"linear\"))\n",
    "print(model_lefteye.summary(), model_facefeatures.summary(), model_merge.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Train on 98306 samples, validate on 4779 samples\n",
      "Epoch 1/200\n",
      "98306/98306 [==============================] - 21s 213us/step - loss: 198.8713 - val_loss: 374.5488\n",
      "Epoch 2/200\n",
      "98306/98306 [==============================] - 18s 182us/step - loss: 171.5658 - val_loss: 354.9275\n",
      "Epoch 3/200\n",
      "98306/98306 [==============================] - 18s 180us/step - loss: 164.1891 - val_loss: 319.4676\n",
      "Epoch 4/200\n",
      "98306/98306 [==============================] - 18s 179us/step - loss: 158.9629 - val_loss: 276.2025\n",
      "Epoch 5/200\n",
      "98306/98306 [==============================] - 18s 181us/step - loss: 155.2042 - val_loss: 244.7587\n",
      "Epoch 6/200\n",
      "98306/98306 [==============================] - 17s 176us/step - loss: 152.0794 - val_loss: 258.6735\n",
      "Epoch 7/200\n",
      "98306/98306 [==============================] - 18s 180us/step - loss: 149.6288 - val_loss: 236.4842\n",
      "Epoch 8/200\n",
      "98306/98306 [==============================] - 17s 175us/step - loss: 147.3140 - val_loss: 232.5546\n",
      "Epoch 9/200\n",
      "98306/98306 [==============================] - 18s 181us/step - loss: 145.3746 - val_loss: 222.1655\n",
      "Epoch 10/200\n",
      "98306/98306 [==============================] - 17s 175us/step - loss: 143.5703 - val_loss: 220.3134\n",
      "Epoch 11/200\n",
      "98306/98306 [==============================] - 17s 177us/step - loss: 142.0796 - val_loss: 216.1462\n",
      "Epoch 12/200\n",
      "98306/98306 [==============================] - 18s 179us/step - loss: 140.4703 - val_loss: 220.1247\n",
      "Epoch 13/200\n",
      "98306/98306 [==============================] - 17s 174us/step - loss: 139.2833 - val_loss: 218.8900\n",
      "Saved model to disk\n",
      "dict_keys(['val_loss', 'loss'])\n"
     ]
    }
   ],
   "source": [
    "opt = Adam(lr=0.001, decay=0.1 / 200)\n",
    "model_merge.compile(loss = 'mae', optimizer = opt )\n",
    "earlystopping = keras.callbacks.EarlyStopping(monitor = 'val_loss',min_delta = 1, patience =2, verbose =0, mode ='auto')\n",
    "\n",
    "history = model_merge.fit([train['left_eye'], train['face_features']], train['gaze_point'][:,:2], \\\n",
    "                validation_data= ([val['left_eye'], val['face_features']],val['gaze_point'][:,:2]),\n",
    "                epochs = 200, batch_size = 32,  callbacks =[earlystopping], verbose=1, shuffle= True)\n",
    "\n",
    "save_model(model_save, model_merge)\n",
    "\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 98306 samples, validate on 4779 samples\n",
      "Epoch 1/100\n",
      "98306/98306 [==============================] - 17s 174us/step - loss: 138.2366 - val_loss: 213.7916\n",
      "Epoch 2/100\n",
      "98306/98306 [==============================] - 17s 176us/step - loss: 136.9764 - val_loss: 213.8881\n",
      "Epoch 3/100\n",
      "98306/98306 [==============================] - 17s 171us/step - loss: 136.0185 - val_loss: 216.3672\n",
      "Epoch 4/100\n",
      "98306/98306 [==============================] - 17s 171us/step - loss: 135.1891 - val_loss: 215.8019\n",
      "Epoch 5/100\n",
      "98306/98306 [==============================] - 17s 174us/step - loss: 134.1756 - val_loss: 210.9907\n",
      "Epoch 6/100\n",
      "98306/98306 [==============================] - 17s 176us/step - loss: 133.3402 - val_loss: 208.0956\n",
      "Epoch 7/100\n",
      "98306/98306 [==============================] - 17s 172us/step - loss: 132.7801 - val_loss: 209.9076\n",
      "Epoch 8/100\n",
      "98306/98306 [==============================] - 17s 174us/step - loss: 132.0865 - val_loss: 212.6254\n",
      "Epoch 9/100\n",
      "98306/98306 [==============================] - 17s 176us/step - loss: 131.2464 - val_loss: 208.7043\n",
      "Epoch 10/100\n",
      "98306/98306 [==============================] - 17s 172us/step - loss: 130.5546 - val_loss: 210.9439\n",
      "Epoch 11/100\n",
      "98306/98306 [==============================] - 17s 173us/step - loss: 129.9222 - val_loss: 206.4276\n",
      "Epoch 12/100\n",
      "98306/98306 [==============================] - 17s 177us/step - loss: 129.3714 - val_loss: 212.9499\n",
      "Epoch 13/100\n",
      "98306/98306 [==============================] - 17s 173us/step - loss: 128.7962 - val_loss: 208.7385\n",
      "Epoch 14/100\n",
      "98306/98306 [==============================] - 17s 173us/step - loss: 128.3364 - val_loss: 207.2222\n",
      "Epoch 15/100\n",
      "98306/98306 [==============================] - 17s 175us/step - loss: 127.7781 - val_loss: 208.8507\n",
      "Epoch 16/100\n",
      "98306/98306 [==============================] - 17s 176us/step - loss: 127.4452 - val_loss: 207.7661\n",
      "Epoch 17/100\n",
      "98306/98306 [==============================] - 17s 171us/step - loss: 127.0749 - val_loss: 208.4949\n",
      "Epoch 18/100\n",
      "98306/98306 [==============================] - 17s 173us/step - loss: 126.4489 - val_loss: 207.1259\n",
      "Epoch 19/100\n",
      "98306/98306 [==============================] - 17s 176us/step - loss: 126.0936 - val_loss: 204.6911\n",
      "Epoch 20/100\n",
      "98306/98306 [==============================] - 17s 173us/step - loss: 125.6444 - val_loss: 201.8240\n",
      "Epoch 21/100\n",
      "98306/98306 [==============================] - 17s 176us/step - loss: 125.3431 - val_loss: 209.6876\n",
      "Epoch 22/100\n",
      "98306/98306 [==============================] - 17s 175us/step - loss: 124.9596 - val_loss: 206.4342\n",
      "Epoch 23/100\n",
      "98306/98306 [==============================] - 17s 175us/step - loss: 124.8318 - val_loss: 207.5082\n",
      "Epoch 24/100\n",
      "98306/98306 [==============================] - 17s 171us/step - loss: 124.3922 - val_loss: 209.9011\n",
      "Epoch 25/100\n",
      "98306/98306 [==============================] - 17s 173us/step - loss: 123.9249 - val_loss: 206.1123\n",
      "Epoch 26/100\n",
      "98306/98306 [==============================] - 17s 176us/step - loss: 123.5185 - val_loss: 208.1020\n",
      "Epoch 27/100\n",
      "98306/98306 [==============================] - 17s 173us/step - loss: 123.5427 - val_loss: 207.8777\n",
      "Epoch 28/100\n",
      "98306/98306 [==============================] - 17s 172us/step - loss: 122.9705 - val_loss: 205.9288\n",
      "Epoch 29/100\n",
      "98306/98306 [==============================] - 17s 175us/step - loss: 122.7732 - val_loss: 202.8252\n",
      "Epoch 30/100\n",
      "98306/98306 [==============================] - 18s 179us/step - loss: 122.5067 - val_loss: 206.1438\n",
      "Epoch 31/100\n",
      "98306/98306 [==============================] - 17s 171us/step - loss: 122.2055 - val_loss: 204.6174\n",
      "Epoch 32/100\n",
      "98306/98306 [==============================] - 17s 173us/step - loss: 121.9829 - val_loss: 204.6443\n",
      "Epoch 33/100\n",
      "98306/98306 [==============================] - 17s 176us/step - loss: 121.7966 - val_loss: 200.0095\n",
      "Epoch 34/100\n",
      "98306/98306 [==============================] - 17s 173us/step - loss: 121.5032 - val_loss: 201.7593\n",
      "Epoch 35/100\n",
      "98306/98306 [==============================] - 17s 172us/step - loss: 121.3634 - val_loss: 202.5350\n",
      "Epoch 36/100\n",
      "98306/98306 [==============================] - 17s 175us/step - loss: 120.8695 - val_loss: 204.0746\n",
      "Epoch 37/100\n",
      "98306/98306 [==============================] - 17s 175us/step - loss: 120.6443 - val_loss: 204.1080\n",
      "Epoch 38/100\n",
      "98306/98306 [==============================] - 17s 171us/step - loss: 120.5953 - val_loss: 203.9226\n",
      "Epoch 39/100\n",
      "98306/98306 [==============================] - 17s 172us/step - loss: 120.3005 - val_loss: 201.9295\n",
      "Epoch 40/100\n",
      "98306/98306 [==============================] - 17s 176us/step - loss: 120.0418 - val_loss: 204.2804\n",
      "Epoch 41/100\n",
      "98306/98306 [==============================] - 17s 174us/step - loss: 120.0767 - val_loss: 201.3953\n",
      "Epoch 42/100\n",
      "98306/98306 [==============================] - 17s 172us/step - loss: 119.7345 - val_loss: 200.9856\n",
      "Epoch 43/100\n",
      "98306/98306 [==============================] - 17s 174us/step - loss: 119.6238 - val_loss: 202.7759\n",
      "Epoch 44/100\n",
      "98306/98306 [==============================] - 17s 176us/step - loss: 119.5390 - val_loss: 204.4129\n",
      "Epoch 45/100\n",
      "38880/98306 [==========>...................] - ETA: 10s - loss: 118.3951"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-4f710b9a8454>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m history = model_merge.fit([train['left_eye'], train['face_features']], train['gaze_point'][:,:2],                 validation_data= ([val['left_eye'], val['face_features']],val['gaze_point'][:,:2]),\n\u001b[0;32m----> 2\u001b[0;31m                 epochs = 100, batch_size = 32,  verbose=1, shuffle= True)\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1710\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1712\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model_merge.fit([train['left_eye'], train['face_features']], train['gaze_point'][:,:2], \\\n",
    "                validation_data= ([val['left_eye'], val['face_features']],val['gaze_point'][:,:2]),\n",
    "                epochs = 100, batch_size = 32,  verbose=1, shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'][1:])\n",
    "plt.plot(history.history['val_loss'][1:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n",
      "dict_keys(['val_loss', 'loss'])\n"
     ]
    }
   ],
   "source": [
    "save_model(model_save, model_merge)\n",
    "\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "Saved model to disk\n",
      "dict_keys(['val_loss', 'loss'])\n"
     ]
    }
   ],
   "source": [
    "model = load_model(model_save)\n",
    "model_save = '/ssd_scratch/cvit/isha/DGAZE2/DGAZE_weights/weights_proposed_approach'\n",
    "save_model(model_save, model)\n",
    "\n",
    "print(history.history.keys())\n",
    "model.compile(loss='mae', optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaze_error(model, data):\n",
    "    scores = model.evaluate([data['left_eye'], data['face_features']], data['gaze_point'][:,:2])\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "98306/98306 [==============================] - 11s 111us/step\n",
      "4779/4779 [==============================] - 0s 88us/step\n",
      "3761/3761 [==============================] - 0s 89us/step\n",
      "Train Error ==>  133.3476467606369\n",
      "Val Error ==>  204.7756923205385\n",
      "Test Error ==>  186.89798304692954\n"
     ]
    }
   ],
   "source": [
    "model = load_model(model_save)\n",
    "model.compile(loss='mae', optimizer=opt)\n",
    "\n",
    "train_error = gaze_error(model, train)\n",
    "val_error = gaze_error(model, val)\n",
    "test_error = gaze_error(model, test)\n",
    "    \n",
    "print(\"Train Error ==> \", train_error)\n",
    "print(\"Val Error ==> \",  val_error)\n",
    "print(\"Test Error ==> \" ,test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for driver in data_split['drivers_test']:\n",
    "\n",
    "#     data_calibrate = dataset(driver_data, [driver], np.arange(1,113))\n",
    "#     model_merge = load_model(model_save)\n",
    "    \n",
    "#     opt = Adam(lr=0.001, decay=0.1 / 200)\n",
    "#     model_merge.compile(loss='mae', optimizer=opt)\n",
    "#     scores = model_merge.evaluate([data_calibrate['left_eye'][2000:], data_calibrate['face_features'][2000:]], data_calibrate['gaze_point'][2000:,:2])\n",
    "#     print(\"====> Before Calibration\", scores)                   \n",
    "\n",
    "#     history = model_merge.fit([data_calibrate['left_eye'][:2000], data_calibrate['face_features'][:2000]], data_calibrate['gaze_point'][:2000,:2], \\\n",
    "#                     validation_data= ([data_calibrate['left_eye'][2000:], data_calibrate['face_features'][2000:]],data_calibrate['gaze_point'][2000:,:2]),\n",
    "#                     epochs = 20, batch_size = 32, verbose=1, shuffle= True)\n",
    "\n",
    "#     scores = model_merge.evaluate([data_calibrate['left_eye'][2000:], data_calibrate['face_features'][2000:]], data_calibrate['gaze_point'][2000:,:2])\n",
    "\n",
    "#     print(\"====> After Calibration\", scores) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 470.43it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 30.48it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 316.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2480, 6)\n",
      "Loaded model from disk\n",
      "2480/2480 [==============================] - 2s 978us/step\n",
      "Test Error ==>  253.85731683546496\n",
      "Train on 1316 samples, validate on 2480 samples\n",
      "Epoch 1/10\n",
      "1316/1316 [==============================] - 7s 5ms/step - loss: 217.3141 - val_loss: 253.2945\n",
      "Epoch 2/10\n",
      "1316/1316 [==============================] - 2s 1ms/step - loss: 215.5906 - val_loss: 252.5813\n",
      "Epoch 3/10\n",
      "1316/1316 [==============================] - 2s 1ms/step - loss: 213.5206 - val_loss: 251.8664\n",
      "Epoch 4/10\n",
      "1316/1316 [==============================] - 2s 1ms/step - loss: 210.8198 - val_loss: 251.3260\n",
      "Epoch 5/10\n",
      "1316/1316 [==============================] - 2s 1ms/step - loss: 208.7282 - val_loss: 250.8947\n",
      "2480/2480 [==============================] - 0s 81us/step\n",
      "Test Error ==> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 495.92it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 32.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 250.89474332255702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 20/20 [00:00<00:00, 373.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 17.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2299, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "2299/2299 [==============================] - 2s 1ms/step\n",
      "Test Error ==>  151.82987633929557\n",
      "Train on 1296 samples, validate on 2299 samples\n",
      "Epoch 1/10\n",
      "1296/1296 [==============================] - 6s 5ms/step - loss: 199.3381 - val_loss: 151.0309\n",
      "Epoch 2/10\n",
      "1296/1296 [==============================] - 2s 1ms/step - loss: 196.3111 - val_loss: 150.3615\n",
      "Epoch 3/10\n",
      "1296/1296 [==============================] - 2s 1ms/step - loss: 193.4979 - val_loss: 149.8555\n",
      "Epoch 4/10\n",
      "1296/1296 [==============================] - 2s 1ms/step - loss: 189.9718 - val_loss: 149.5299\n",
      "Epoch 5/10\n",
      "1296/1296 [==============================] - 2s 1ms/step - loss: 187.8156 - val_loss: 149.2875\n",
      "2299/2299 [==============================] - 0s 80us/step\n",
      "Test Error ==>  149.28748530935027\n",
      "Total test error --> 202.84359658738026 200.09111431595363\n"
     ]
    }
   ],
   "source": [
    "te_error = 0; tr_error = 0\n",
    "for driver in data_split['drivers_val']:\n",
    "    data_calibrate = dataset(driver_data, [driver], np.arange(1,15))\n",
    "                         \n",
    "    te_calibrate = dataset(driver_data, [driver], data_split['sequence_val'])\n",
    "\n",
    "    print(te_calibrate['gaze_point'].shape)\n",
    "    opt = Adam(lr=0.0000001)\n",
    "    \n",
    "    model_merge = load_model(model_save)\n",
    "    for layer in model_merge.layers[:1]:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    model_merge.compile(loss = 'mae', optimizer = opt)\n",
    "    \n",
    "    error = gaze_error(model_merge, te_calibrate)\n",
    "    tr_error += error\n",
    "    print(\"Test Error ==> \" ,error)\n",
    "              \n",
    "\n",
    "        \n",
    "    model_merge.fit([data_calibrate['left_eye'], data_calibrate['face_features']], data_calibrate['gaze_point'][:,:2], \\\n",
    "                validation_data= ([te_calibrate['left_eye'], te_calibrate['face_features']],te_calibrate['gaze_point'][:,:2]),\n",
    "                epochs = 10, batch_size = 8, callbacks = [earlystopping], verbose=1, shuffle= True)\n",
    "\n",
    "\n",
    "    error = gaze_error(model_merge, te_calibrate)\n",
    "    te_error += error\n",
    "    print(\"Test Error ==> \" ,error)\n",
    "                         \n",
    "print(\"Total test error -->\", tr_error/len(data_split['drivers_val']), te_error/len(data_split['drivers_val']))\n",
    "                         \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 437.02it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 28.47it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 404.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1743, 6)\n",
      "Loaded model from disk\n",
      "1743/1743 [==============================] - 2s 1ms/step\n",
      "Test Error ==>  189.73342510536355\n",
      "Train on 1291 samples, validate on 1743 samples\n",
      "Epoch 1/10\n",
      "1291/1291 [==============================] - 5s 4ms/step - loss: 201.6692 - val_loss: 189.7588\n",
      "Epoch 2/10\n",
      "1291/1291 [==============================] - 1s 574us/step - loss: 201.1549 - val_loss: 189.7831\n",
      "Epoch 3/10\n",
      "1291/1291 [==============================] - 1s 577us/step - loss: 202.2824 - val_loss: 189.8053\n",
      "Epoch 4/10\n",
      "1291/1291 [==============================] - 1s 574us/step - loss: 200.8743 - val_loss: 189.8328\n",
      "Epoch 5/10\n",
      "1291/1291 [==============================] - 1s 577us/step - loss: 201.2706 - val_loss: 189.8586\n",
      "Epoch 6/10\n",
      "1291/1291 [==============================] - 1s 576us/step - loss: 201.0266 - val_loss: 189.8846\n",
      "Epoch 7/10\n",
      "1291/1291 [==============================] - 1s 577us/step - loss: 198.9562 - val_loss: 189.9084\n",
      "Epoch 8/10\n",
      "1291/1291 [==============================] - 1s 574us/step - loss: 200.0484 - val_loss: 189.9347\n",
      "Epoch 9/10\n",
      "1291/1291 [==============================] - 1s 574us/step - loss: 200.7821 - val_loss: 189.9608\n",
      "Epoch 10/10\n",
      "1291/1291 [==============================] - 1s 576us/step - loss: 199.5809 - val_loss: 189.9864\n",
      "1743/1743 [==============================] - 0s 79us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 468.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 30.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error ==>  189.98639864327916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 20/20 [00:00<00:00, 320.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2018, 6)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded model from disk\n",
      "2018/2018 [==============================] - 2s 1ms/step\n",
      "Test Error ==>  184.44893477622298\n",
      "Train on 1317 samples, validate on 2018 samples\n",
      "Epoch 1/10\n",
      "1317/1317 [==============================] - 6s 4ms/step - loss: 224.0761 - val_loss: 184.4357\n",
      "Epoch 2/10\n",
      "1317/1317 [==============================] - 1s 604us/step - loss: 223.1319 - val_loss: 184.4304\n",
      "Epoch 3/10\n",
      "1317/1317 [==============================] - 1s 606us/step - loss: 222.3167 - val_loss: 184.4243\n",
      "Epoch 4/10\n",
      "1317/1317 [==============================] - 1s 605us/step - loss: 222.5670 - val_loss: 184.4185\n",
      "Epoch 5/10\n",
      "1317/1317 [==============================] - 1s 604us/step - loss: 221.2289 - val_loss: 184.4110\n",
      "Epoch 6/10\n",
      "1317/1317 [==============================] - 1s 604us/step - loss: 222.2403 - val_loss: 184.4067\n",
      "Epoch 7/10\n",
      "1317/1317 [==============================] - 1s 602us/step - loss: 222.0567 - val_loss: 184.4017\n",
      "Epoch 8/10\n",
      "1317/1317 [==============================] - 1s 602us/step - loss: 221.9851 - val_loss: 184.3997\n",
      "Epoch 9/10\n",
      "1317/1317 [==============================] - 1s 604us/step - loss: 221.1106 - val_loss: 184.3934\n",
      "Epoch 10/10\n",
      "1317/1317 [==============================] - 1s 612us/step - loss: 221.1689 - val_loss: 184.3866\n",
      "2018/2018 [==============================] - 0s 82us/step\n",
      "Test Error ==>  184.38661635430054\n",
      "Total test error --> 187.09117994079327 187.18650749878987\n"
     ]
    }
   ],
   "source": [
    "te_error = 0; tr_error = 0\n",
    "for driver in data_split['drivers_test']:\n",
    "    data_calibrate = dataset(driver_data, [driver], np.arange(1,15))\n",
    "                         \n",
    "    te_calibrate = dataset(driver_data, [driver], data_split['sequence_test'])\n",
    "\n",
    "    print(te_calibrate['gaze_point'].shape)\n",
    "    \n",
    "#     opt = Adam(lr=0.000000009)\n",
    "    opt = Adam(lr=0.00000001)\n",
    "    model_merge = load_model(model_save)\n",
    "    for layer in model_merge.layers[:1]:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    model_merge.compile(loss = 'mae', optimizer = opt)\n",
    "    \n",
    "    error = gaze_error(model_merge, te_calibrate)\n",
    "    tr_error += error\n",
    "    print(\"Test Error ==> \" ,error)\n",
    "              \n",
    "\n",
    "        \n",
    "    model_merge.fit([data_calibrate['left_eye'], data_calibrate['face_features']], data_calibrate['gaze_point'][:,:2], \\\n",
    "                validation_data= ([te_calibrate['left_eye'], te_calibrate['face_features']],te_calibrate['gaze_point'][:,:2]),\n",
    "                epochs = 10, batch_size = 16, verbose=1, shuffle= True)\n",
    "\n",
    "\n",
    "    error = gaze_error(model_merge, te_calibrate)\n",
    "    te_error += error\n",
    "    print(\"Test Error ==> \" ,error)\n",
    "                         \n",
    "print(\"Total test error -->\", tr_error/len(data_split['drivers_test']), te_error/len(data_split['drivers_val']))\n",
    "                         \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
